resources:
  # Let SkyPilot find the best available GPU across all clouds
  accelerators: {
    H200:1,           # 141GB - Best for largest models
    H100:1,           # 80GB
    A100-80GB:1,      # 80GB
    A100:1,           # 40GB
    L40S:1,           # 48GB
    L40:1,            # 48GB
    L4:1,             # 24GB - Minimum for most models
    RTX6000-Ada:1,    # 48GB
    RTXA6000:1,       # 48GB
    RTX4090:1,        # 24GB
  }
  
  # Try all clouds - no spot for interactive
  any_of:
    - {infra: lambda, use_spot: false}
    - {infra: runpod, use_spot: false}
    - {infra: nebius, use_spot: false}

  autostop: true  # Stop after default idle minutes (5).

# Working directory (optional) containing the project codebase.
# Its contents are synced to ~/sky_workdir/ on the cluster.
workdir: .

# Typical use: pip install -r requirements.txt
# Invoked under the workdir (i.e., can use its files).
setup: |
  echo "Running setup."
  uv sync

# Interactive setup - SSH in to run benchmarks manually
run: |
  echo "Interactive cluster ready!"
  echo "SSH in with: sky ssh interactive"
  echo "Then run benchmarks manually using:"
  echo ""
  echo "Classification:"
  echo "  uv run clip_benchmark eval --pretrained_model MODEL,PRETRAINED --dataset DATASET --task zeroshot_classification --output '/clip_eval_runner_results/{dataset}_{pretrained}_{model}_{language}_{task}.json'"
  echo ""
  echo "Retrieval (use webdataset format):"
  echo "  uv run clip_benchmark eval --pretrained_model MODEL,PRETRAINED --dataset wds/DATASET --dataset_root 'https://huggingface.co/datasets/clip-benchmark/wds_{dataset_cleaned}/tree/main' --task zeroshot_retrieval --output '/clip_eval_runner_results/{dataset}_{pretrained}_{model}_{language}_{task}.json'"

 
